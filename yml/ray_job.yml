apiVersion: ray.io/v1
kind: RayJob
metadata:
  name: ray_transnet
spec:
  # submissionMode specifies how RayJob submits the Ray job to the RayCluster.
  # The default value is "K8sJobMode", meaning RayJob will submit the Ray job via a submitter Kubernetes Job.
  # The alternative value is "HTTPMode", indicating that KubeRay will submit the Ray job by sending an HTTP request to the RayCluster.
  # submissionMode: "K8sJobMode"
  entrypoint: python ray_pipeline.py
  # shutdownAfterJobFinishes specifies whether the RayCluster should be deleted after the RayJob finishes. Default is false.
  # shutdownAfterJobFinishes: false

  # ttlSecondsAfterFinished specifies the number of seconds after which the RayCluster will be deleted after the RayJob finishes.
  # ttlSecondsAfterFinished: 10

  # activeDeadlineSeconds is the duration in seconds that the RayJob may be active before
  # KubeRay actively tries to terminate the RayJob; value must be positive integer.
  # activeDeadlineSeconds: 120

  # RuntimeEnvYAML represents the runtime environment configuration provided as a multi-line YAML string.
  # See https://docs.ray.io/en/latest/ray-core/handling-dependencies.html for details.
  # (New in KubeRay version 1.0.)
  runtimeEnvYAML: |
    pip:
      - requests
      - psycopg2-binary
      - oci
      - pandas
      - numpy
      - json
      - pyarrow

    env_vars:
      counter_name: "test_counter"
    working_dir: "https://github.com/krishnawin/visionmlstudio/archive/refs/heads/master.zip"
    

  # Suspend specifies whether the RayJob controller should create a RayCluster instance.
  # If a job is applied with the suspend field set to true, the RayCluster will not be created and we will wait for the transition to false.
  # If the RayCluster is already created, it will be deleted. In the case of transition to false, a new RayCluster will be created.
  # suspend: false

  # rayClusterSpec specifies the RayCluster instance to be created by the RayJob controller.
  rayClusterSpec:
    rayVersion: '2.41.0' # should match the Ray version in the image of the containers
    # Ray head pod template
    headGroupSpec:
      # The `rayStartParams` are used to configure the `ray start` command.
      # See https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayStartParams.md for the default settings of `rayStartParams` in KubeRay.
      # See https://docs.ray.io/en/latest/cluster/cli.html#ray-start for all available options in `rayStartParams`.
      rayStartParams: {}
      #pod template
      template:
        spec:
          containers:
            - name: ray-head
              image: krishnamoorthya/ray-ffmpeg
              ports:
                - containerPort: 6379
                  name: gcs-server
                - containerPort: 8265 # Ray dashboard
                  name: dashboard
                - containerPort: 10001
                  name: client
              resources:
                limits:
                  cpu: "1"
                requests:
                  cpu: "200m"
              volumeMounts:
                - mountPath: /etc/oci/
                  name: yt-config
              env:
                - name: PG_DBNAME
                  valueFrom:
                    secretKeyRef:
                      name: fitcntr
                      key: PG_DBNAME
                - name: PG_USER
                  valueFrom:
                    secretKeyRef:
                      name: fitcntr
                      key: PG_USER
                - name: PG_PASS
                  valueFrom:
                    secretKeyRef:
                      name: fitcntr
                      key: PG_PASS
                - name: PG_HOST
                  valueFrom:
                    secretKeyRef:
                      name: fitcntr
                      key: PG_HOST
                - name: PG_PORT
                  valueFrom:
                    secretKeyRef:
                      name: fitcntr
                      key: PG_PORT
                - name: access_key
                  valueFrom:
                    secretKeyRef:
                      name: s3
                      key: access_key
                - name: secret_key
                  valueFrom:
                    secretKeyRef:
                      name: s3
                      key: secret_key
                - name: namespace
                  valueFrom:
                    secretKeyRef:
                      name: s3
                      key: namespace
                - name: region
                  valueFrom:
                    secretKeyRef:
                      name: s3
                      key: region
          volumes:
            - name: yt-config
              secret:
                  secretName: oci-config
    workerGroupSpecs:
      # the pod replicas in this group typed worker
      - replicas: 1
        minReplicas: 1
        maxReplicas: 5
        # logical group name, for this called small-group, also can be functional
        groupName: small-group
        # The `rayStartParams` are used to configure the `ray start` command.
        # See https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayStartParams.md for the default settings of `rayStartParams` in KubeRay.
        # See https://docs.ray.io/en/latest/cluster/cli.html#ray-start for all available options in `rayStartParams`.
        rayStartParams: {}
        #pod template
        template:
          spec:
            containers:
              - name: ray-worker # must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc'
                image: krishnamoorthya/ray-ffmpeg
                resources:
                  limits:
                    cpu: "1"
                  requests:
                    cpu: "200m"
                volumeMounts:
                  - mountPath: /etc/oci
                    name: yt-config
                env:
                  - name: PG_DBNAME
                    valueFrom:
                      secretKeyRef:
                        name: fitcntr
                        key: PG_DBNAME
                  - name: PG_USER
                    valueFrom:
                      secretKeyRef:
                        name: fitcntr
                        key: PG_USER
                  - name: PG_PASS
                    valueFrom:
                      secretKeyRef:
                        name: fitcntr
                        key: PG_PASS
                  - name: PG_HOST
                    valueFrom:
                      secretKeyRef:
                        name: fitcntr
                        key: PG_HOST
                  - name: PG_PORT
                    valueFrom:
                      secretKeyRef:
                        name: fitcntr
                        key: PG_PORT
                  - name: access_key
                    valueFrom:
                      secretKeyRef:
                        name: s3
                        key: access_key
                  - name: secret_key
                    valueFrom:
                      secretKeyRef:
                        name: s3
                        key: secret_key
                  - name: namespace
                    valueFrom:
                      secretKeyRef:
                        name: s3
                        key: namespace
                  - name: region
                    valueFrom:
                      secretKeyRef:
                        name: s3
                        key: region
            volumes:
              - name: yt-config
                secret:
                      secretName: oci-config
